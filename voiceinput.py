from vosk import Model, KaldiRecognizer
import json
import pyperclip
import pyautogui
import pyaudio
import time
import sys
from threading import Thread

class VoiceInputModule:
    def __init__(self):
        try:
            self.model = Model('vosk-model-small-cn-0.22')
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("è¯·ç¡®è®¤ï¼š1.æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ 2.è·¯å¾„æ˜¯å¦æ­£ç¡® 3.æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´")
            sys.exit(1)
        self.timeout = 4  # æ— å£°éŸ³è¶…æ—¶æ—¶é—´
        self.running = False
        self.last_active = time.time()  # æ·»åŠ æœ€åæ´»åŠ¨æ—¶é—´è®°å½•
    #éŸ³é¢‘è¯†åˆ«æ ¸å¿ƒé€»è¾‘
    def _recognize_audio(self):
        # åˆå§‹åŒ–PyAudio
        p = pyaudio.PyAudio()
        try:
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=8000
            )
        except Exception as e:
            print(f"æ— æ³•æ‰“å¼€éº¦å…‹é£: {str(e)}")
            self.running = False
            return
        # åˆ›å»ºVOSKè¯†åˆ«å™¨
        recognizer = KaldiRecognizer(self.model, 16000)
        print("\nğŸ¤ å¼€å§‹ç›‘å¬...ï¼ˆè¯´ä¸­æ–‡å³å¯ï¼‰")

        try:
            while self.running:
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = stream.read(4000, exception_on_overflow=False)
                # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
                self.last_active = time.time()
                # å¤„ç†å®Œæ•´è¯†åˆ«ç»“æœ
                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.FinalResult())
                    if result['text'] != '':
                        # è°ƒç”¨æ–‡æœ¬è¾“å…¥æ–¹æ³•
                        self._input_text(result['text'])
                        return
                else:
                    partial = json.loads(recognizer.PartialResult())['partial']
                    if partial:
                        print(f"\rğŸ™ è¯†åˆ«ä¸­: {partial}    ", end='')
                # å…¨å±€è¶…æ—¶æ£€æµ‹
                if time.time() - self.last_active > self.timeout:
                    print("\nâ° è†å¬è¶…æ—¶ï¼Œè‡ªåŠ¨åœæ­¢")
                    return
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            self.running = False
            print("éº¦å…‹é£å·²é‡Šæ”¾")
    #æ–‡æœ¬è¾“å…¥æ–¹æ³•
    def _input_text(self, text):
        text = text.replace(' ', '')
        try:
            # å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿
            pyperclip.copy(text)
            # æ¨¡æ‹ŸCtrl+Vç²˜è´´æ“ä½œ
            pyautogui.hotkey('ctrl', 'v')
            print(f"\nâœ… å·²è¾“å…¥: {text}")
        except Exception as e:
            print(f"\nâŒ è¾“å…¥å¤±è´¥: {str(e)}")
    #å¯åŠ¨ç›‘å¬
    def start_listening(self):
        if not self.running:
            self.running = True
            self.last_active = time.time()  # é‡ç½®è®¡æ—¶å™¨
            Thread(target=self._recognize_audio, daemon=True).start()
        else:
            print("å·²ç»åœ¨ç›‘å¬çŠ¶æ€")

    def stop_listening(self):
        """å¼ºåˆ¶åœæ­¢ç›‘å¬"""
        if self.running:
            self.running = False
            print("æ‰‹åŠ¨åœæ­¢ç›‘å¬")

# æµ‹è¯•ç”¨ä¾‹
if __name__ == "__main__":
    print("=== è¯­éŸ³è¾“å…¥æµ‹è¯• ===")
    print("è¯·ç¡®ä¿ï¼š")
    print("1. éº¦å…‹é£å·²è¿æ¥")
    print("2. æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
    print("3. å½“å‰çª—å£å¯æ¥å—æ–‡æœ¬è¾“å…¥")

    vim = VoiceInputModule()
    vim.start_listening()

    # ä¸»å¾ªç¯ç­‰å¾…æ¨¡å—è‡ªåŠ¨åœæ­¢
    while vim.running:
        time.sleep(0.1)
    print("æµ‹è¯•ç»“æŸ")
